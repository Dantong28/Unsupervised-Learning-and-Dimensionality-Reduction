{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#dataset: http://archive.ics.uci.edu/ml/datasets/Forest+Fires\n",
    "#0-5: X, Y, month, day, FFMC, DMC\n",
    "#6-11: DC, ISI, temp, RH, wind, rain\n",
    "#12: area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and edit datasets\n",
    "#Load Forest Fire\n",
    "file_dir_ff = \"/Users/dantongzhu/Documents/Spring 2019/Machine Learning/project 3/forestfires.csv\"\n",
    "df_ff = pd.read_csv(file_dir_ff, header=None)\n",
    "#Load WIne Quality\n",
    "file_dir_wq = \"/Users/dantongzhu/Documents/Spring 2019/Machine Learning/project 3/winequality-red.csv\"\n",
    "df_wq = pd.read_csv(file_dir_wq, sep = ';', header = None)\n",
    "\n",
    "#Edit Forest Fire\n",
    "df_ff.columns = df_ff.iloc[0]\n",
    "df_ff = df_ff.drop([0])\n",
    "map_month = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
    "df_ff['month'] = df_ff['month'].map(map_month)\n",
    "map_day = {'mon':1, 'tue':2, 'wed':3, 'thu':4, 'fri':5, 'sat':6, 'sun':7}\n",
    "df_ff['day'] = df_ff['day'].map(map_day)\n",
    "df_ff['area'] = pd.to_numeric(df_ff['area'])\n",
    "df_ff['label'] = (df_ff['area'] > 5).astype(int)  #1 if area > 5, 0 otherwise\n",
    "X_ff = df_ff.loc[:,'X':'rain']\n",
    "labels_true_ff = df_ff['label'].values\n",
    "#Edit Wine Quality\n",
    "df_wq.columns = df_wq.iloc[0]\n",
    "df_wq = df_wq.drop([0])\n",
    "df_wq['label'] = df_wq['quality']\n",
    "X_wq = df_wq.loc[:,'fixed acidity':'alcohol']\n",
    "labels_true_wq = df_wq['label'].values\n",
    "\n",
    "#Two datasets together\n",
    "dataset_names = [\"Forest Fire\", \"Wine Quality\"]\n",
    "df_set = [df_ff, df_wq]\n",
    "X_set = [X_ff, X_wq]\n",
    "labels_true_set = [labels_true_ff, labels_true_wq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 1: n = 1,  0.0 0.0 0.0 0.0\n",
      "dataset 1: n = 2,  0.0011941418684816418 -0.001659052871171824 -0.0053793634539512185 -0.002166085291688866\n",
      "dataset 1: n = 3,  -0.0023073416831620487 -0.00037618706696917293 -0.010229800298327766 -0.0022476578027251647\n",
      "dataset 1: n = 4,  0.0001389404340863122 -0.0018727446625084597 0.007137633873153912 -0.001848144544056776\n",
      "dataset 1: n = 5,  0.0011956582928114945 0.0002919385152548323 0.0004791698950912424 -0.0002880562549549173\n",
      "dataset 1: n = 6,  0.0012129080030807014 0.00013227881325848507 0.003021108216271848 -0.002258191094315635\n",
      "dataset 1: n = 7,  0.0026409855571749067 -0.0013014659650810113 0.005390775243614017 0.0009585991124069028\n",
      "dataset 1: n = 8,  0.00011469340484574985 -0.0020566604505987364 0.006423783057297361 -0.00026323298198213234\n",
      "dataset 1: n = 9,  0.0009236429427588837 -0.001940647508285803 -0.0001849449553925356 0.001090828399093662\n",
      "dataset 1: n = 10,  -4.501816322117948e-06 -0.0024721524066315275 0.0005974551950105497 -0.0026740036260482175\n",
      "dataset 1: n = 11,  0.0004286106182770573 -0.0017247185493582476 -0.0017487700120063713 -0.0015577299358324468\n",
      "dataset 1: n = 12,  0.00046493817803930327 -0.0017759202072501468 -0.0013853984752224301 -0.0006173841570014159\n",
      "dataset 1: n = 13,  0.0011247918634025023 0.0018085305643842163 -0.0020615916017902546 0.003423108403733556\n",
      "dataset 1: n = 14,  -0.0006810795255368128 2.417788054219771e-05 -0.0017817617286733545 0.004144065292830914\n",
      "dataset 1: n = 15,  0.001215303904545962 0.0058401710524932735 -0.0019217303747373457 0.005354001668211544\n",
      "dataset 1: n = 16,  0.0006187606687483105 0.0015859544297402097 -0.0016618511963906654 0.0028352927320380583\n",
      "dataset 1: n = 17,  0.0009356965101700615 0.003820477419787436 -0.0018402464247034872 0.004441669910981967\n",
      "dataset 1: n = 18,  0.0019463299159457547 0.003196852221879911 -0.0009759796432124484 0.004312614927213057\n",
      "dataset 1: n = 19,  0.0017999958153367495 0.003572168980687087 -0.0009968492082597143 0.004455853819838731\n",
      "dataset 1: n = 20,  0.0029060370652941895 0.004410612394388625 0.0001499379267350697 0.005083608381786934\n",
      "dataset 1: n = 21,  0.0015175708583404174 0.008138844265822872 0.000349096084437444 0.0022608262600401397\n",
      "dataset 1: n = 22,  0.0012486937453584776 0.00796249291343249 0.00026901386957674337 0.008752034572719045\n",
      "dataset 1: n = 23,  0.003044216631004954 0.01103884585987719 0.0004869338949758485 0.007332837064661335\n",
      "dataset 1: n = 24,  0.0013501579923448162 0.002542438955107901 0.00044653516819151277 0.005366836300864842\n",
      "dataset 1: n = 25,  0.0021149712840996086 0.005164105196482525 0.0003252709403661504 0.0043866611990599404\n",
      "dataset 1: n = 26,  0.0023554267109987064 0.010597785967206511 -0.00021136811338096466 0.006779206837923353\n",
      "dataset 1: n = 27,  0.0021510705602267623 0.006002956413471613 -0.0007886405697521002 0.007393409132026735\n",
      "dataset 1: n = 28,  0.0013791094343523565 0.002702749915575322 -0.00044581603400843347 0.007018661724127721\n",
      "dataset 1: n = 29,  0.0022532824039575715 0.003590372608771575 -0.00033654214045034277 0.008261016393230347\n",
      "dataset 1: n = 30,  0.0010658524030509318 0.0022751113886665683 -0.00015002272857279807 0.008158655849300525\n",
      "dataset 1: n = 31,  0.0005066684254647831 0.0015985795175230925 -6.498483869025827e-05 0.007664366597354808\n",
      "dataset 1: n = 32,  0.001327988129226752 0.005327534156165575 7.005473770226481e-05 0.0077792640613814305\n",
      "dataset 1: n = 33,  0.0019175173298520893 0.00738992633764507 1.638010998661567e-05 0.007150832139320084\n",
      "dataset 1: n = 34,  0.0012839787960243992 0.0031297181173405887 -4.970768859019873e-05 0.006590714011767952\n",
      "dataset 1: n = 35,  0.0014960123993291341 0.005460766395145907 -7.746019170368473e-05 0.00616991077527648\n",
      "dataset 1: n = 36,  0.0008721408718731872 0.005028839813403047 0.00014518629235274008 0.00556706601257274\n",
      "dataset 1: n = 37,  0.0007713495161952591 0.004523781001517878 0.0005664045039971377 0.00544461509484487\n",
      "dataset 1: n = 38,  0.0015630322202709226 0.007348960063028672 0.0007583699039868194 0.008793081668482049\n",
      "dataset 1: n = 39,  0.0010903503779601596 0.0021581449569121 0.0006787581111594275 0.008620922011214529\n",
      "dataset 1: n = 40,  0.0006959582308214983 0.0018759210524076204 0.0006801708149626265 0.008009306676192773\n",
      "dataset 2: n = 1,  0.0 -2.47213557359195e-15 0.0 -2.47213557359195e-15\n",
      "dataset 2: n = 2,  -0.003192039673600158 0.034984837740144915 0.020531742276419497 0.008203884457364976\n",
      "dataset 2: n = 3,  0.002357455355172735 0.03335796524850895 0.022436444482763072 0.048950107765100705\n",
      "dataset 2: n = 4,  -0.005112585894278884 0.037429298097631354 0.06621656442811284 0.08113078937197507\n",
      "dataset 2: n = 5,  -0.004797817360311893 0.03280432579878591 0.02595932450448881 0.026324496126219288\n",
      "dataset 2: n = 6,  -0.005394768940921144 0.036126854510274954 0.06943388347993497 0.07498008301631354\n",
      "dataset 2: n = 7,  0.001984971073900616 0.034171507167961586 0.07379632396258325 0.07841040151248085\n",
      "dataset 2: n = 8,  0.0001005656396540399 0.03646063231290608 0.05046653152154688 0.0638920385355369\n",
      "dataset 2: n = 9,  0.0018338151503714457 0.03689295029858203 0.018631830569035366 0.03997171650969313\n",
      "dataset 2: n = 10,  -0.0020343426680453393 0.03563468027257939 0.02109521138447399 0.033343930562607996\n",
      "dataset 2: n = 11,  -0.0035952551951383034 0.032871337413962275 0.025119149216212628 0.04950101278327595\n",
      "dataset 2: n = 12,  -0.0030280195492173997 0.03409944684079646 0.037742125806307536 0.0677669758060383\n",
      "dataset 2: n = 13,  -0.0047058699350713785 0.03191415947190884 0.04044517081506465 0.06837104245415253\n",
      "dataset 2: n = 14,  -0.004817953797384763 0.03416532767690884 0.03015121382985486 0.06468721547037258\n",
      "dataset 2: n = 15,  -0.0014669909173035947 0.03024129472275494 0.04200588693389353 0.06824563731838125\n",
      "dataset 2: n = 16,  -0.0011859743594093226 0.033716077470869237 0.054545589876038615 0.07486270061553903\n",
      "dataset 2: n = 17,  -0.0011761591087158102 0.03329713752654751 0.04262583702789599 0.06687697472624353\n",
      "dataset 2: n = 18,  -0.0023632817956978423 0.03107803592351264 0.0340799040521297 0.06175453007306534\n",
      "dataset 2: n = 19,  0.001511165232463939 0.034578313994168906 0.03381975218388763 0.06625500848866807\n",
      "dataset 2: n = 20,  0.0017119050584092428 0.03206834877758972 0.026003884459818126 0.063754362843702\n",
      "dataset 2: n = 21,  -0.0009934230539870843 0.03282972431451192 0.03058881325646785 0.06457956760671249\n",
      "dataset 2: n = 22,  -0.0030505847107556027 0.030926598174901964 0.018885766842668912 0.05396378770065437\n",
      "dataset 2: n = 23,  -0.0017583915012229483 0.03218998956923781 0.018031861198499588 0.05407940677843737\n",
      "dataset 2: n = 24,  0.000519542836848404 0.032051423723809626 0.01636872807238989 0.04775016451404473\n",
      "dataset 2: n = 25,  -0.0002767064696976929 0.03202623756841053 0.030075570656254234 0.0684852827148085\n",
      "dataset 2: n = 26,  -0.0026087981644440767 0.029150226382899345 0.029001232732054426 0.06830641957331605\n",
      "dataset 2: n = 27,  0.0010579141351352854 0.029179282477951974 0.014630441655654084 0.052846198992778946\n",
      "dataset 2: n = 28,  -0.0002811057996421455 0.032365293322143475 0.012523223202818559 0.04551444837475292\n",
      "dataset 2: n = 29,  -3.426986191394375e-05 0.028632562467240386 0.01545310855257542 0.05675843899434292\n",
      "dataset 2: n = 30,  -0.00025136205205857315 0.029063145539088935 0.007563828028378891 0.041981622776293394\n",
      "dataset 2: n = 31,  0.0007353714823878765 0.03023785508610376 0.017071903298385288 0.04949268253905504\n",
      "dataset 2: n = 32,  -0.0005381254988665634 0.029264224538548034 0.01707783350815956 0.049926091816808606\n",
      "dataset 2: n = 33,  -0.0009359611170234128 0.03353352453394485 0.016459105743134462 0.04688595590326992\n",
      "dataset 2: n = 34,  -0.0007255695821620679 0.030880386776200093 0.015914845932256238 0.04543890746722716\n",
      "dataset 2: n = 35,  -3.145511712530347e-05 0.029856753422949016 0.03109560446058816 0.06048162423121527\n",
      "dataset 2: n = 36,  -0.0007233795033466545 0.02824848587712247 0.02252832222277654 0.05955599041401839\n",
      "dataset 2: n = 37,  0.0004853268016315208 0.028951069607807394 0.015242779452192916 0.04874640627977732\n",
      "dataset 2: n = 38,  -0.00149643894417135 0.031165162585887373 0.008959512550939429 0.042015503423585676\n",
      "dataset 2: n = 39,  -0.0006976848815558534 0.03080495712068748 0.018942640903653083 0.04564329702177478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 2: n = 40,  -0.0007038575819627548 0.029350155058108666 0.010735400790019337 0.04486893655200981\n"
     ]
    }
   ],
   "source": [
    "#Task 1\n",
    "#Clustering: K means and Expectation Maximization\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "\n",
    "k = 5 #number of trials\n",
    "n_range = range(1,41)\n",
    "\n",
    "ARI_kmeans_array_list = []\n",
    "MI_kmeans_array_list = []\n",
    "ARI_em_array_list = []\n",
    "MI_em_array_list = []\n",
    "\n",
    "for j in range(0, 2):\n",
    "    df = df_set[j]\n",
    "    X = X_set[j]\n",
    "    labels_true = labels_true_set[j]\n",
    "\n",
    "    ARI_kmeans_array = np.array([])\n",
    "    MI_kmeans_array = np.array([])\n",
    "    ARI_em_array = np.array([])\n",
    "    MI_em_array = np.array([])\n",
    "\n",
    "    for n in n_range:\n",
    "        tot_ARI_kmeans = 0\n",
    "        tot_MI_kmeans = 0\n",
    "        tot_ARI_em = 0\n",
    "        tot_MI_em = 0\n",
    "        \n",
    "        for i in range(0, k):\n",
    "            #train\n",
    "            kmeans = KMeans(n_clusters=n, random_state=0).fit(X)\n",
    "            em =  GaussianMixture(n_components= n, max_iter = 500, random_state=0).fit(X)\n",
    "            #predict\n",
    "            labels_pred_kmeans = kmeans.predict(X)\n",
    "            labels_pred_em = em.predict(X)\n",
    "            #evaluation\n",
    "            ARI_kmeans = metrics.adjusted_rand_score(labels_true, labels_pred_kmeans)\n",
    "            MI_kmeans = metrics.adjusted_mutual_info_score(labels_true, labels_pred_kmeans, average_method='arithmetic')\n",
    "            ARI_em = metrics.adjusted_rand_score(labels_true, labels_pred_em)\n",
    "            MI_em = metrics.adjusted_mutual_info_score(labels_true, labels_pred_em, average_method='arithmetic')\n",
    "\n",
    "            tot_ARI_kmeans = tot_ARI_kmeans + ARI_kmeans\n",
    "            tot_MI_kmeans = tot_MI_kmeans + MI_kmeans\n",
    "            tot_ARI_em = tot_ARI_em + ARI_em\n",
    "            tot_MI_em = tot_MI_em + MI_em\n",
    "\n",
    "        ARI_kmeans_array = np.append(ARI_kmeans_array, tot_ARI_kmeans/k)\n",
    "        MI_kmeans_array = np.append(MI_kmeans_array, tot_MI_kmeans/k)\n",
    "        ARI_em_array = np.append(ARI_em_array, tot_ARI_em/k)\n",
    "        MI_em_array = np.append(MI_em_array, tot_MI_em/k)\n",
    "        print (\"dataset \" + str(j+1) + \": n = \" + str(n) + \", \",\n",
    "               str(tot_ARI_kmeans/k), str(tot_MI_kmeans/k), str(tot_ARI_em/k), str(tot_MI_em/k))\n",
    "        \n",
    "    ARI_kmeans_array_list.append(ARI_kmeans_array)\n",
    "    MI_kmeans_array_list.append(MI_kmeans_array)\n",
    "    ARI_em_array_list.append(ARI_em_array)\n",
    "    MI_em_array_list.append(MI_em_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1 continue\n",
    "#Clustering Plot\n",
    "%matplotlib qt\n",
    "#%matplotlib inline\n",
    "\n",
    "for j in range(0, 2):\n",
    "    ARI_kmeans_array = ARI_kmeans_array_list[j]\n",
    "    MI_kmeans_array = MI_kmeans_array_list[j]\n",
    "    ARI_em_array = ARI_em_array_list[j]\n",
    "    MI_em_array = MI_em_array_list[j]\n",
    "    dataset_name = dataset_names[j]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(dataset_name + \" Clustering\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Evaluation of Performance\")\n",
    "    \n",
    "    plt.plot(n_range, ARI_kmeans_array, marker='', linewidth=2, color = \"red\", label=\"K means ARI\")\n",
    "    plt.plot(n_range, MI_kmeans_array, marker='', linestyle='dashed', linewidth=2, color = \"red\", label=\"K means MI\")\n",
    "    plt.plot(n_range, ARI_em_array, marker='', linewidth=2, color = \"blue\", label=\"EM ARI\")\n",
    "    plt.plot(n_range, MI_em_array, marker='', linestyle='dashed', linewidth=2, color = \"blue\", label=\"EM MI\")\n",
    "\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#based on the result, we will choose to do 5 clusters for both datasets for the rest of the experiments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K means prediction distribution: {0: 134, 1: 89, 2: 190, 3: 60, 4: 44}\n",
      "EM prediction distribution: {0: 12, 1: 86, 2: 163, 3: 213, 4: 43}\n",
      "Forest Fire n = 5 clustering\n",
      "K means ARI = 0.0011956582928114945, MI = 0.0002919385152548323\n",
      "EM ARI = 0.0004791698950912424, MI = -0.0002880562549549173\n",
      "K means prediction distribution: {0: 69, 1: 450, 2: 298, 3: 184, 4: 598}\n",
      "EM prediction distribution: {0: 39, 1: 812, 2: 160, 3: 241, 4: 347}\n",
      "Wine Quality n = 5 clustering\n",
      "K means ARI = -0.004797817360311893, MI = 0.03280432579878591\n",
      "EM ARI = 0.025959324504488814, MI = 0.026324496126219288\n"
     ]
    }
   ],
   "source": [
    "#Task 1 continue\n",
    "#Plot Histogram of Clustering Results\n",
    "%matplotlib qt\n",
    "\n",
    "n = 5 #number of clusters for both datasets\n",
    "for j in range(0, 2):\n",
    "    df = df_set[j]\n",
    "    X = X_set[j]\n",
    "    labels_true = labels_true_set[j]\n",
    "    dataset_name = dataset_names[j]\n",
    "\n",
    "    #train\n",
    "    kmeans = KMeans(n_clusters=n, random_state=0).fit(X)\n",
    "    em =  GaussianMixture(n_components= n, max_iter = 500, random_state=0).fit(X)\n",
    "    #predict\n",
    "    labels_pred_kmeans = kmeans.predict(X)\n",
    "    labels_pred_em = em.predict(X)\n",
    "    \n",
    "    #count occurance\n",
    "    #a = numpy.array([0, 3, 0, 1, 0, 1, 2, 1, 0, 0, 0, 0, 1, 3, 4])\n",
    "    unique_KM, counts_KM = np.unique(labels_pred_kmeans, return_counts=True)\n",
    "    unique_EM, counts_EM = np.unique(labels_pred_em, return_counts=True)\n",
    "    print (\"K means prediction distribution: \" + str(dict(zip(unique_KM, counts_KM))))\n",
    "    print (\"EM prediction distribution: \" + str(dict(zip(unique_EM, counts_EM))))\n",
    "    \n",
    "    #evaluate\n",
    "    ARI_kmeans = metrics.adjusted_rand_score(labels_true, labels_pred_kmeans)\n",
    "    MI_kmeans = metrics.adjusted_mutual_info_score(labels_true, labels_pred_kmeans, average_method='arithmetic')\n",
    "    ARI_em = metrics.adjusted_rand_score(labels_true, labels_pred_em)\n",
    "    MI_em = metrics.adjusted_mutual_info_score(labels_true, labels_pred_em, average_method='arithmetic')\n",
    "    #print evaluation\n",
    "    print (dataset_name + \" n = 5 clustering\")\n",
    "    print (\"K means ARI = \" + str(ARI_kmeans) + \", MI = \" + str(MI_kmeans))\n",
    "    print (\"EM ARI = \" + str(ARI_em) + \", MI = \" + str(MI_em))\n",
    "    \n",
    "    #plot k means\n",
    "    plt.figure()\n",
    "    plt.title(dataset_name + \" K means Histogram, n = \" + str(n))\n",
    "    plt.hist(labels_pred_kmeans, rwidth=0.8, bins=n)\n",
    "    plt.xlabel(\"Components\")\n",
    "\n",
    "    #plot EM\n",
    "    plt.figure()\n",
    "    plt.title(dataset_name + \" Expectation Maximization Histogram, n = \" + str(n))\n",
    "    plt.hist(labels_pred_em, rwidth=0.8, bins=n)\n",
    "    plt.xlabel(\"Components\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Fire PCA Eigenvalues\n",
      "[6.35315829e+04 2.13360020e+03 2.74912192e+02 3.01035993e+01\n",
      " 1.47925583e+01 9.92633332e+00 5.79544765e+00 4.12721416e+00\n",
      " 2.79215516e+00 1.08229112e+00 8.67634461e-01 8.29958565e-02]\n",
      "Wine Quality PCA Eigenvalues\n",
      "[1.13380708e+03 5.79354108e+01 3.10130228e+00 1.81941532e+00\n",
      " 1.04634036e+00 4.13967294e-02 2.31926578e-02 1.13464685e-02\n",
      " 1.00779841e-02 1.45499755e-03 5.61482667e-07]\n"
     ]
    }
   ],
   "source": [
    "#Task 2\n",
    "#PCA and eigenvalues, plot histogram\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib qt\n",
    "\n",
    "for j in range(0, 2):\n",
    "    df = df_set[j]\n",
    "    X = X_set[j]\n",
    "    labels_true = labels_true_set[j]\n",
    "    dataset_name = dataset_names[j]\n",
    "    \n",
    "    #get PCA\n",
    "    pca = PCA()\n",
    "    pca_compos = pca.fit_transform(X)\n",
    "    pca_X = pd.DataFrame(data = pca_compos)\n",
    "    #compute eigenvalues\n",
    "    eigenvalues = pca.explained_variance_\n",
    "    print (dataset_name + \" PCA Eigenvalues\")\n",
    "    print (eigenvalues)\n",
    "    #plot (log of) eigenvalues\n",
    "    eigenvalues_log = np.log10(eigenvalues) \n",
    "    plt.figure()\n",
    "    plt.title(\"PCA Eigenvalues: \" + dataset_name)\n",
    "    plt.xlabel(\"Components\")\n",
    "    plt.ylabel(\"Log of Eigenvalues\")\n",
    "    plt.bar(range(1, len(eigenvalues)+1), eigenvalues_log)\n",
    "\n",
    "#Result:\n",
    "#FF may need more target components for running PCA than WQ, because lots of WQ eigenvalues are low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Fire:\n",
      "kurtosis = 1189.9755756296656\n",
      "[3.458816837467751, -0.2576685563859691, 2.808314786706574, 1.1190231492582132, 1.058504361767504, 42.08059881043827, 0.6468491009038964, -1.2031347289122774, 24.420225547202126, 420.67888774953224, 103.5708774640647, -1.1812068710951127]\n",
      "count = 5.0 out of 12\n",
      "Wine Quality:\n",
      "kurtosis = 241.38689681548203\n",
      "[4.509727895082629, 19.37073115243356, 6.830016151734096, 33.96013299181132, 2.3832310936921512, 45.144666526612745, 2.5098494255747363, 3.4007241682839098, -0.975834769436859, 3.092727537658525, -0.30589303998762585]\n",
      "count = 7.0 out of 11\n"
     ]
    }
   ],
   "source": [
    "#Task 2: ICA and kurtosis, plot histogram\n",
    "from sklearn.decomposition import FastICA\n",
    "from scipy.stats import kurtosis\n",
    "%matplotlib qt\n",
    "\n",
    "k = 5  #number of trials\n",
    "for j in range(0, 2):\n",
    "    df = df_set[j]\n",
    "    X = X_set[j]\n",
    "    labels_true = labels_true_set[j]\n",
    "    dataset_name = dataset_names[j]\n",
    "    #ICA\n",
    "    tot_kurt_mag = 0\n",
    "    tot_count = 0\n",
    "    for i in range(0, k):\n",
    "        ica = FastICA(max_iter = 500)\n",
    "        ica_compos = ica.fit_transform(X)\n",
    "        ica_X = pd.DataFrame(data = ica_compos)\n",
    "        #Compute Kurtosis\n",
    "        kurt_arr = []\n",
    "        count = 0\n",
    "        for col in ica_X:\n",
    "            kurt = kurtosis(ica_X[col])\n",
    "            kurt_arr.append(kurt)\n",
    "            if (kurt > 3):\n",
    "                count = count+1\n",
    "        kurt_vector = np.array(kurt_arr)\n",
    "        kurt_mag = np.sum(kurt_vector*2)\n",
    "        tot_kurt_mag = tot_kurt_mag + kurt_mag\n",
    "        tot_count = tot_count + count\n",
    "    kurt_mag = tot_kurt_mag/k\n",
    "    count = tot_count/k\n",
    "    print (dataset_name + \":\")\n",
    "    print (\"kurtosis = \" + str(kurt_mag))\n",
    "    print (kurt_arr)\n",
    "    print (\"count = \" + str(count) + \" out of \" + str(len(df.columns)-2))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"ICA Kurtosis: \" + dataset_name)\n",
    "    plt.xlabel(\"Components\")\n",
    "    plt.ylabel(\"Kurtosis\")\n",
    "    plt.axhline(y=3, color = \"red\")\n",
    "    plt.bar(range(1, len(ica_X.columns)+1), kurt_arr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Fire 0 131763.97448005716\n",
      "Forest Fire 1 176893.92250487593\n",
      "Forest Fire 10 21923.546198413398\n",
      "Forest Fire 20 5513.346257572894\n",
      "Forest Fire 30 1462.8177017311052\n",
      "Forest Fire 40 23.221361862678602\n",
      "Forest Fire 50 52.89315894265413\n",
      "Forest Fire 75 2.2543495574599133\n",
      "Forest Fire 100 0.5293795769844023\n",
      "Forest Fire 125 0.09390801964406721\n",
      "Forest Fire 150 9.268080737733995e-05\n",
      "Forest Fire 175 1.4169013759224883e-06\n",
      "Forest Fire 200 1.302637319538649e-07\n",
      "Wine Quality 0 2394.0958446583386\n",
      "Wine Quality 1 2284.731900709841\n",
      "Wine Quality 10 4502.03833465898\n",
      "Wine Quality 20 2373.474862358412\n",
      "Wine Quality 30 1905.2351857025292\n",
      "Wine Quality 40 1544.2778823128933\n",
      "Wine Quality 50 134.54802186547704\n",
      "Wine Quality 75 1732.9953728641742\n",
      "Wine Quality 100 653.2018375569518\n",
      "Wine Quality 125 6.357297377119459\n",
      "Wine Quality 150 10.261169396945634\n",
      "Wine Quality 175 17.91402587224002\n",
      "Wine Quality 200 38.72166865549826\n"
     ]
    }
   ],
   "source": [
    "#Task 2: Random Projection\n",
    "from sklearn import random_projection\n",
    "%matplotlib qt\n",
    "\n",
    "num_trials = [0,1, 10, 20, 30, 40, 50, 75, 100, 125, 150, 175, 200]\n",
    "for j in range(0, 2):\n",
    "    df = df_set[j]\n",
    "    X = X_set[j]\n",
    "    labels_true = labels_true_set[j]\n",
    "    dataset_name = dataset_names[j]\n",
    "    \n",
    "    curr_X = X\n",
    "    var_mag_arr = []\n",
    "    count = 0\n",
    "    while count <= num_trials[len(num_trials)-1]:\n",
    "        #calculate variance\n",
    "        if count in num_trials:\n",
    "            if (count == 0):\n",
    "                rp_X = curr_X\n",
    "            var_arr = np.array([])\n",
    "            for col in rp_X:\n",
    "                col_arr = np.array(rp_X[col].astype(float).values)\n",
    "                var = np.var(col_arr)\n",
    "                var_arr = np.append(var_arr, var)\n",
    "            var_mag = np.sum(var_arr*2)\n",
    "            var_mag_arr.append(var_mag)\n",
    "            print (dataset_name, count, var_mag)\n",
    "        #run RP\n",
    "        rp = random_projection.GaussianRandomProjection(n_components = len(X.columns))\n",
    "        rp_compos = rp.fit_transform(curr_X)     \n",
    "        rp_X = pd.DataFrame(data = rp_compos)\n",
    "        curr_X = rp_X\n",
    "        count = count + 1\n",
    "    #plot\n",
    "    plt.figure()\n",
    "    plt.title(dataset_name + \" Random Projection Variance Over Time\")\n",
    "    plt.xlabel(\"Number of Trials\")\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.plot(num_trials, var_mag_arr, marker='', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3\n",
    "#Clustering experiments on the data after dimensionality reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn import random_projection\n",
    "from sklearn import metrics\n",
    "from scipy.stats import kurtosis\n",
    "%matplotlib qt\n",
    "\n",
    "PCA_dim_set = [6, 4]  #Target dimensions for PCA results, according to the eigenvalues results in Task 2\n",
    "RP_runs = [10, 10]\n",
    "\n",
    "pca_X_set = []\n",
    "ica_X_set = []\n",
    "rp_X_set = []\n",
    "\n",
    "for j in range(0, 2):\n",
    "    df = df_set[j]\n",
    "    X = X_set[j]\n",
    "    labels_true = labels_true_set[j]\n",
    "    dataset_name = dataset_names[j]\n",
    "    \n",
    "    #Generate the new features\n",
    "    #PCA\n",
    "    pca = PCA(n_components = PCA_dim_set[j])\n",
    "    pca_compos = pca.fit_transform(X)\n",
    "    pca_X = pd.DataFrame(data = pca_compos)\n",
    "    pca_X_set.append(pca_X)\n",
    "    \n",
    "    #ICA   \n",
    "    ica = FastICA(max_iter = 500)\n",
    "    ica_compos = ica.fit_transform(X)\n",
    "    ica_X = pd.DataFrame(data = ica_compos)\n",
    "    #Delte new features that have abs(kurtosis) <= 3\n",
    "    to_delete = []\n",
    "    for col in ica_X.columns:\n",
    "        if kurtosis(ica_X[col]) <= 3:\n",
    "            to_delete.append(col)\n",
    "    ica_X = ica_X.drop(to_delete, axis=1)\n",
    "    ica_X_set.append(ica_X)\n",
    "    \n",
    "    #RP\n",
    "    count = 0\n",
    "    curr_X = X\n",
    "    while count < RP_runs[j]:\n",
    "        rp = random_projection.GaussianRandomProjection(n_components = len(X.columns))\n",
    "        rp_compos = rp.fit_transform(curr_X)     \n",
    "        rp_X = pd.DataFrame(data = rp_compos)\n",
    "        curr_X = rp_X\n",
    "        count = count + 1\n",
    "    rp_X_set.append(rp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Forest Fire\n",
      "n = 5 done\n",
      "n = 10 done\n",
      "n = 15 done\n",
      "n = 20 done\n",
      "Dataset 2: Wine Quality\n",
      "n = 5 done\n",
      "n = 10 done\n",
      "n = 15 done\n",
      "n = 20 done\n"
     ]
    }
   ],
   "source": [
    "#Task 3 continue\n",
    "#Compare clustering results on the new features and plot\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "%matplotlib qt\n",
    "\n",
    "dim_red_names = [\"PCA\", \"ICA\", \"RP\"]\n",
    "n_range = range(1,21)\n",
    "\n",
    "for j in range(0, 2):\n",
    "    df = df_set[j]\n",
    "    X = X_set[j]\n",
    "    labels_true = labels_true_set[j]\n",
    "    dataset_name = dataset_names[j]\n",
    "    print (\"Dataset \" + str(j+1) + \": \" + dataset_name)\n",
    "    \n",
    "    new_X_set = [pca_X_set[j], ica_X_set[j], rp_X_set[j]]\n",
    "    ARI_kmeans_new_raw_PCA, ARI_kmeans_new_raw_ICA, ARI_kmeans_new_raw_RP = ([], [], [])\n",
    "    ARI_kmeans_new_true_PCA, ARI_kmeans_new_true_ICA, ARI_kmeans_new_true_RP = ([], [], [])\n",
    "    ARI_em_new_raw_PCA, ARI_em_new_raw_ICA, ARI_em_new_raw_RP = ([], [], [])\n",
    "    ARI_em_new_true_PCA, ARI_em_new_true_ICA, ARI_em_new_true_RP = ([], [], [])\n",
    "    ARI_kmeans_raw_true_arr, ARI_em_raw_true_arr = ([], [])\n",
    "    \n",
    "    for n in n_range:  #n = number of clusters\n",
    "        #clustering on raw data\n",
    "        kmeans = KMeans(n_clusters=n, random_state=0).fit(X)\n",
    "        em =  GaussianMixture(n_components= n, max_iter = 500, random_state=0).fit(X)\n",
    "        labels_pred_kmeans_raw = kmeans.predict(X)\n",
    "        labels_pred_em_raw = em.predict(X)\n",
    "        #ARI: raw vs true\n",
    "        ARI_kmeans_raw_true = metrics.adjusted_rand_score(labels_pred_kmeans_raw, labels_true)\n",
    "        ARI_em_raw_true = metrics.adjusted_rand_score(labels_pred_em_raw, labels_true)\n",
    "        ARI_kmeans_raw_true_arr.append(ARI_kmeans_raw_true)\n",
    "        ARI_em_raw_true_arr.append(ARI_em_raw_true)\n",
    "        \n",
    "        #clustering on new data\n",
    "        for m in range(0, len(dim_red_names)):\n",
    "            #define the new features and the name\n",
    "            new_X = new_X_set[m]\n",
    "            dim_red_name = dim_red_names[m]\n",
    "            \n",
    "            #Run K means and EM\n",
    "            kmeans = KMeans(n_clusters=n, random_state=0).fit(new_X)\n",
    "            em =  GaussianMixture(n_components= n, max_iter = 500, random_state=0).fit(new_X)\n",
    "            labels_pred_kmeans_new = kmeans.predict(new_X)\n",
    "            labels_pred_em_new = em.predict(new_X)\n",
    "            \n",
    "            #Compute ARI values\n",
    "            #new vs old\n",
    "            ARI_kmeans_new_raw = metrics.adjusted_rand_score(labels_pred_kmeans_new, labels_pred_kmeans_raw)\n",
    "            ARI_em_new_raw = metrics.adjusted_rand_score(labels_pred_em_new, labels_pred_em_raw)\n",
    "            #new vs true\n",
    "            ARI_kmeans_new_true = metrics.adjusted_rand_score(labels_pred_kmeans_new, labels_true)\n",
    "            ARI_em_new_true = metrics.adjusted_rand_score(labels_pred_em_new, labels_true)\n",
    "            if dim_red_name == \"PCA\":\n",
    "                ARI_kmeans_new_raw_PCA.append(ARI_kmeans_new_raw)\n",
    "                ARI_em_new_raw_PCA.append(ARI_em_new_raw)\n",
    "                ARI_kmeans_new_true_PCA.append(ARI_kmeans_new_true)\n",
    "                ARI_em_new_true_PCA.append(ARI_em_new_true)\n",
    "            if dim_red_name == \"ICA\":\n",
    "                ARI_kmeans_new_raw_ICA.append(ARI_kmeans_new_raw)\n",
    "                ARI_em_new_raw_ICA.append(ARI_em_new_raw)\n",
    "                ARI_kmeans_new_true_ICA.append(ARI_kmeans_new_true)\n",
    "                ARI_em_new_true_ICA.append(ARI_em_new_true)\n",
    "            if dim_red_name == \"RP\":\n",
    "                ARI_kmeans_new_raw_RP.append(ARI_kmeans_new_raw)\n",
    "                ARI_em_new_raw_RP.append(ARI_em_new_raw)\n",
    "                ARI_kmeans_new_true_RP.append(ARI_kmeans_new_true)\n",
    "                ARI_em_new_true_RP.append(ARI_em_new_true)\n",
    "        if np.remainder(n, 5) == 0:\n",
    "            print (\"n = \" + str(n) + \" done\")\n",
    "        \n",
    "    #plot\n",
    "    #Compare to the true labeling\n",
    "    #K means compare to True\n",
    "    plt.figure()\n",
    "    plt.title(dataset_name + \" Clustering Similarity: Compare to True Labels\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"ARI score\")\n",
    "    #k means\n",
    "    plt.plot(n_range, ARI_kmeans_new_true_PCA, marker='', color = 'b', linewidth=2, label=\"k means PCA\")\n",
    "    plt.plot(n_range, ARI_kmeans_new_true_ICA, marker='', color = 'm', linewidth=2, label=\"k means ICA\")\n",
    "    plt.plot(n_range, ARI_kmeans_new_true_RP, marker='', color = 'y', linewidth=2, label=\"k means RP\")\n",
    "    plt.plot(n_range, ARI_kmeans_raw_true_arr, marker='', color = 'r', linewidth=2, label=\"k means RAW\")\n",
    "    #EM\n",
    "    plt.plot(n_range, ARI_em_new_true_PCA, marker='', color = 'b', linestyle = 'dashed', linewidth=2, label=\"EM PCA\")\n",
    "    plt.plot(n_range, ARI_em_new_true_ICA, marker='', color = 'm', linestyle = 'dashed', linewidth=2, label=\"EM ICA\")\n",
    "    plt.plot(n_range, ARI_em_new_true_RP, marker='', color = 'y', linestyle = 'dashed', linewidth=2, label=\"EM RP\")\n",
    "    plt.plot(n_range, ARI_em_raw_true_arr, marker='', color = 'r', linestyle = 'dashed', linewidth=2, label=\"EM RAW\")\n",
    "    plt.legend()\n",
    "    \n",
    "    #K means NEW vs RAW\n",
    "    plt.figure()\n",
    "    plt.title(dataset_name + \" Clustering Similarity: New Features VS. Raw Features\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"ARI score\")\n",
    "    #K means\n",
    "    plt.plot(n_range, ARI_kmeans_new_raw_PCA, marker='', color = 'b', linewidth=2, label=\"k means PCA\")\n",
    "    plt.plot(n_range, ARI_kmeans_new_raw_ICA, marker='', color = 'm', linewidth=2, label=\"k means ICA\")\n",
    "    plt.plot(n_range, ARI_kmeans_new_raw_RP, marker='', color = 'y', linewidth=2, label=\"k means RP\")\n",
    "    #EM\n",
    "    plt.plot(n_range, ARI_em_new_raw_PCA, marker='', color = 'b', linestyle = 'dashed', linewidth=2, label=\"EM PCA\")\n",
    "    plt.plot(n_range, ARI_em_new_raw_ICA, marker='', color = 'm', linestyle = 'dashed', linewidth=2, label=\"EM ICA\")\n",
    "    plt.plot(n_range, ARI_em_new_raw_RP, marker='', color = 'y', linestyle = 'dashed', linewidth=2, label=\"EM RP\")\n",
    "    plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA done\n",
      "ICA 2 done\n",
      "RP done\n",
      "RP 2 done\n"
     ]
    }
   ],
   "source": [
    "#Task 4\n",
    "#Rerun neural network on the newly projected data\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn import random_projection\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "k = 5 #number of trials\n",
    "\n",
    "#Will focus on the Forest Fire dataset only\n",
    "df = df_set[0]\n",
    "X = X_set[0]\n",
    "labels_true = labels_true_set[0]\n",
    "dataset_name = dataset_names[0]\n",
    "\n",
    "#Trials to do for each feature transformation\n",
    "n_compo_range = range(1, 13)  #target number of components\n",
    "ICA_kurt_th_range = [-5, -1, 0, 1, 2.5, 3, 100]    #target threshold for kurtosis for each component for ICA\n",
    "RP_runs_range = [1, 3, 5, 7, 9, 13, 16, 18, 20]     #number of runs for RP\n",
    "\n",
    "#PCA\n",
    "pca_X_set = []\n",
    "for n in n_compo_range:\n",
    "    pca = PCA(n_components = n)\n",
    "    pca_compos = pca.fit_transform(X)\n",
    "    pca_X = pd.DataFrame(data = pca_compos)\n",
    "    pca_X_set.append(pca_X)\n",
    "print (\"PCA done\")\n",
    "\n",
    "#ICA\n",
    "ica_X_set = []\n",
    "n_compo_ICA = []\n",
    "ica = FastICA(max_iter = 500)\n",
    "ica_compos = ica.fit_transform(X)\n",
    "ica_X = pd.DataFrame(data = ica_compos)\n",
    "for th in ICA_kurt_th_range:\n",
    "    #Delte new features that have kurtosis <= th\n",
    "    to_delete = []\n",
    "    for col in ica_X.columns:\n",
    "        if kurtosis(ica_X[col]) <= th:\n",
    "            to_delete.append(col)\n",
    "    new_X = ica_X.drop(to_delete, axis=1)\n",
    "    ica_X_set.append(new_X)\n",
    "    n_compo_ICA.append(len(new_X.columns))\n",
    "print (\"ICA done\")\n",
    "\n",
    "#ICA 2\n",
    "ica_X_set_2 = []\n",
    "for n in n_compo_range:\n",
    "    ica = FastICA(n_components = n, max_iter = 500)\n",
    "    ica_compos = ica.fit_transform(X)\n",
    "    ica_X = pd.DataFrame(data = ica_compos)\n",
    "    ica_X_set_2.append(ica_X)\n",
    "print (\"ICA 2 done\")\n",
    "\n",
    "#RP\n",
    "rp_X_set = []\n",
    "count = 0\n",
    "curr_X = X\n",
    "while count < RP_runs_range[len(RP_runs_range) - 1]:\n",
    "    rp = random_projection.GaussianRandomProjection(n_components = len(X.columns))\n",
    "    rp_compos = rp.fit_transform(curr_X)\n",
    "    rp_X = pd.DataFrame(data = rp_compos)\n",
    "    count = count + 1\n",
    "    if count in RP_runs_range:\n",
    "        rp_X_set.append(rp_X)\n",
    "    curr_X = rp_X\n",
    "print (\"RP done\")\n",
    "\n",
    "#RP 2\n",
    "rp_X_set_2 = []\n",
    "for n in n_compo_range:\n",
    "    rp = random_projection.GaussianRandomProjection(n_components = n)\n",
    "    rp_compos = rp.fit_transform(curr_X)     \n",
    "    rp_X = pd.DataFrame(data = rp_compos)\n",
    "    rp_X_set_2.append(rp_X)\n",
    "print (\"RP 2 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy = 0.7454545454545455, time = 1.5949316024780273\n",
      "\n",
      "PCA\n",
      "n = 1 accuracy = 0.7079303675048356, time = 1.0626091003417968\n",
      "n = 2 accuracy = 0.7206963249516442, time = 1.3513918399810791\n",
      "n = 3 accuracy = 0.764796905222437, time = 1.9181020736694336\n",
      "n = 4 accuracy = 0.7783365570599614, time = 1.825807237625122\n",
      "n = 5 accuracy = 0.755899419729207, time = 1.3001336574554443\n",
      "n = 6 accuracy = 0.7636363636363637, time = 1.5943079948425294\n",
      "n = 7 accuracy = 0.790715667311412, time = 1.777907943725586\n",
      "n = 8 accuracy = 0.7767891682785301, time = 1.7524633407592773\n",
      "n = 9 accuracy = 0.7895551257253386, time = 1.8776212215423584\n",
      "n = 10 accuracy = 0.7845261121856867, time = 1.5892150402069092\n",
      "n = 11 accuracy = 0.7899419729206965, time = 1.6911307334899903\n",
      "n = 12 accuracy = 0.7733075435203094, time = 1.5095304012298585\n",
      "\n",
      "ICA select kurtosis\n",
      "th = -5, n = 12 accuracy = 0.7079303675048356, time = 0.347103214263916\n",
      "th = -1, n = 10 accuracy = 0.7114119922630561, time = 0.6558905601501465\n",
      "th = 0, n = 8 accuracy = 0.7114119922630561, time = 0.5800065994262695\n",
      "th = 1, n = 6 accuracy = 0.7183752417794971, time = 0.8012192726135254\n",
      "th = 2.5, n = 6 accuracy = 0.711798839458414, time = 0.6305285930633545\n",
      "th = 3, n = 5 accuracy = 0.7183752417794972, time = 1.2985148429870605\n",
      "th = 100, n = 2 accuracy = 0.7079303675048356, time = 0.39571471214294435\n",
      "\n",
      "ICA No selection of kurtosis\n",
      "n = 1 accuracy = 0.7079303675048356, time = 0.3554680347442627\n",
      "n = 2 accuracy = 0.7079303675048356, time = 0.34360294342041015\n",
      "n = 3 accuracy = 0.7079303675048356, time = 0.33574204444885253\n",
      "n = 4 accuracy = 0.7079303675048356, time = 0.40424232482910155\n",
      "n = 5 accuracy = 0.7079303675048356, time = 0.36994204521179197\n",
      "n = 6 accuracy = 0.7079303675048356, time = 0.30675582885742186\n",
      "n = 7 accuracy = 0.7079303675048356, time = 0.3656569004058838\n",
      "n = 8 accuracy = 0.7079303675048356, time = 0.34175782203674315\n",
      "n = 9 accuracy = 0.7079303675048356, time = 0.3429758071899414\n",
      "n = 10 accuracy = 0.7079303675048356, time = 0.31110057830810545\n",
      "n = 11 accuracy = 0.7079303675048356, time = 0.34998092651367185\n",
      "n = 12 accuracy = 0.7137330754352031, time = 0.6545280456542969\n",
      "\n",
      "RP multiple runs\n",
      "n = 1 accuracy = 0.7381044487427466, time = 1.5530204772949219\n",
      "n = 3 accuracy = 0.7237911025145068, time = 1.5678606986999513\n",
      "n = 5 accuracy = 0.7129593810444874, time = 1.3132755756378174\n",
      "n = 7 accuracy = 0.7133462282398453, time = 1.6506524562835694\n",
      "n = 9 accuracy = 0.7098646034816248, time = 1.1725972652435304\n",
      "n = 13 accuracy = 0.7087040618955512, time = 1.0945705413818358\n",
      "n = 16 accuracy = 0.7087040618955512, time = 0.9212284564971924\n",
      "n = 18 accuracy = 0.7087040618955512, time = 1.1199506759643554\n",
      "n = 20 accuracy = 0.7094777562862669, time = 1.0392117500305176\n",
      "\n",
      "RP reduce dimension\n",
      "n = 1 accuracy = 0.7079303675048356, time = 0.9700104713439941\n",
      "n = 2 accuracy = 0.7087040618955512, time = 0.7471787929534912\n",
      "n = 3 accuracy = 0.7079303675048356, time = 0.5796774864196778\n",
      "n = 4 accuracy = 0.7102514506769826, time = 1.5184479713439942\n",
      "n = 5 accuracy = 0.7079303675048356, time = 0.6188546180725097\n",
      "n = 6 accuracy = 0.7125725338491297, time = 1.5637759685516357\n",
      "n = 7 accuracy = 0.709477756286267, time = 1.1677247047424317\n",
      "n = 8 accuracy = 0.7090909090909091, time = 1.2826204299926758\n",
      "n = 9 accuracy = 0.7079303675048356, time = 0.8425713539123535\n",
      "n = 10 accuracy = 0.7079303675048356, time = 0.9264378070831298\n",
      "n = 11 accuracy = 0.7087040618955512, time = 1.7226723670959472\n",
      "n = 12 accuracy = 0.711798839458414, time = 1.7303854465484618\n"
     ]
    }
   ],
   "source": [
    "#Task 4 continue\n",
    "#Run NN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "k = 5  #number of trials\n",
    "\n",
    "#NN On raw data\n",
    "tot_accuracy = 0\n",
    "tot_time = 0\n",
    "for i in range (0, k):\n",
    "    start = time.time()\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "    clf.fit(X, labels_true)\n",
    "    predictions = clf.predict(X)\n",
    "    delta = abs(predictions - labels_true)\n",
    "    accuracy = 1 - np.mean(delta)\n",
    "    original_time = time.time() - start\n",
    "    tot_accuracy = tot_accuracy + accuracy\n",
    "    tot_time = tot_time + original_time\n",
    "original_accuracy = tot_accuracy/k\n",
    "original_time = tot_time/k\n",
    "print (\"Original accuracy = \" + str(original_accuracy) + \", time = \" + str(original_time))\n",
    "print (\"\")\n",
    "\n",
    "# NN on PCA results\n",
    "print (\"PCA\")\n",
    "PCA_accu_arr = []\n",
    "PCA_time_arr = []\n",
    "for j in range(0, len(pca_X_set)):\n",
    "    new_X = pca_X_set[j]\n",
    "    n = n_compo_range[j]\n",
    "    tot_accuracy = 0\n",
    "    tot_time = 0\n",
    "    for i in range (0, k):\n",
    "        start = time.time()\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "        clf.fit(new_X, labels_true)\n",
    "        predictions = clf.predict(new_X)\n",
    "        delta = abs(predictions - labels_true)\n",
    "        accuracy = 1 - np.mean(delta)\n",
    "        original_time = time.time() - start\n",
    "        tot_accuracy = tot_accuracy + accuracy\n",
    "        tot_time = tot_time + original_time\n",
    "    avg_accuracy = tot_accuracy/k\n",
    "    avg_time = tot_time/k\n",
    "    PCA_accu_arr.append(avg_accuracy)\n",
    "    PCA_time_arr.append(avg_time)\n",
    "    print (\"n = \" + str(n) + \" accuracy = \" + str(avg_accuracy) + \", time = \" + str(avg_time))\n",
    "print (\"\")\n",
    "\n",
    "# NN on ICA results\n",
    "print (\"ICA select kurtosis\")\n",
    "ICA_accu_arr = []\n",
    "ICA_time_arr = []\n",
    "for j in range(0, len(ica_X_set)):\n",
    "    new_X = ica_X_set[j]\n",
    "    th = ICA_kurt_th_range[j]\n",
    "    n = len(new_X.columns)\n",
    "    tot_accuracy = 0\n",
    "    tot_time = 0\n",
    "    for i in range (0, k):\n",
    "        start = time.time()\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "        clf.fit(new_X, labels_true)\n",
    "        predictions = clf.predict(new_X)\n",
    "        delta = abs(predictions - labels_true)\n",
    "        accuracy = 1 - np.mean(delta)\n",
    "        original_time = time.time() - start\n",
    "        tot_accuracy = tot_accuracy + accuracy\n",
    "        tot_time = tot_time + original_time\n",
    "    avg_accuracy = tot_accuracy/k\n",
    "    avg_time = tot_time/k\n",
    "    ICA_accu_arr.append(avg_accuracy)\n",
    "    ICA_time_arr.append(avg_time)\n",
    "    print (\"th = \" + str(th) + \", n = \" + str(n) + \n",
    "           \" accuracy = \" + str(avg_accuracy) + \", time = \" + str(avg_time))\n",
    "print (\"\")\n",
    "\n",
    "print (\"ICA No selection of kurtosis\")\n",
    "ICA_2_accu_arr = []\n",
    "ICA_2_time_arr = []\n",
    "for j in range(0, len(ica_X_set_2)):\n",
    "    new_X = ica_X_set_2[j]\n",
    "    n = n_compo_range[j]\n",
    "    tot_accuracy = 0\n",
    "    tot_time = 0\n",
    "    for i in range (0, k):\n",
    "        start = time.time()\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "        clf.fit(new_X, labels_true)\n",
    "        predictions = clf.predict(new_X)\n",
    "        delta = abs(predictions - labels_true)\n",
    "        accuracy = 1 - np.mean(delta)\n",
    "        original_time = time.time() - start\n",
    "        tot_accuracy = tot_accuracy + accuracy\n",
    "        tot_time = tot_time + original_time\n",
    "    avg_accuracy = tot_accuracy/k\n",
    "    avg_time = tot_time/k\n",
    "    ICA_2_accu_arr.append(avg_accuracy)\n",
    "    ICA_2_time_arr.append(avg_time)\n",
    "    print (\"n = \" + str(n) + \" accuracy = \" + str(avg_accuracy) + \", time = \" + str(avg_time))\n",
    "print (\"\")\n",
    "\n",
    "\n",
    "# NN on RP results\n",
    "RP_accu_arr = []\n",
    "RP_time_arr = []\n",
    "print (\"RP multiple runs\")\n",
    "for j in range(0, len(rp_X_set)):\n",
    "    new_X = rp_X_set[j]\n",
    "    n = RP_runs_range[j]\n",
    "    tot_accuracy = 0\n",
    "    tot_time = 0\n",
    "    for i in range (0, k):\n",
    "        start = time.time()\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "        clf.fit(new_X, labels_true)\n",
    "        predictions = clf.predict(new_X)\n",
    "        delta = abs(predictions - labels_true)\n",
    "        accuracy = 1 - np.mean(delta)\n",
    "        original_time = time.time() - start\n",
    "        tot_accuracy = tot_accuracy + accuracy\n",
    "        tot_time = tot_time + original_time\n",
    "    avg_accuracy = tot_accuracy/k\n",
    "    avg_time = tot_time/k\n",
    "    RP_accu_arr.append(avg_accuracy)\n",
    "    RP_time_arr.append(avg_time)\n",
    "    print (\"n = \" + str(n) + \" accuracy = \" + str(avg_accuracy) + \", time = \" + str(avg_time))\n",
    "print (\"\")\n",
    "\n",
    "# NN on RP results\n",
    "print (\"RP reduce dimension\")\n",
    "RP_2_accu_arr = []\n",
    "RP_2_time_arr = []\n",
    "for j in range(0, len(rp_X_set_2)):\n",
    "    new_X = rp_X_set_2[j]\n",
    "    n = n_compo_range[j]\n",
    "    tot_accuracy = 0\n",
    "    tot_time = 0\n",
    "    for i in range (0, k):\n",
    "        start = time.time()\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "        clf.fit(new_X, labels_true)\n",
    "        predictions = clf.predict(new_X)\n",
    "        delta = abs(predictions - labels_true)\n",
    "        accuracy = 1 - np.mean(delta)\n",
    "        original_time = time.time() - start\n",
    "        tot_accuracy = tot_accuracy + accuracy\n",
    "        tot_time = tot_time + original_time\n",
    "    avg_accuracy = tot_accuracy/k\n",
    "    avg_time = tot_time/k\n",
    "    RP_2_accu_arr.append(avg_accuracy)\n",
    "    RP_2_time_arr.append(avg_time)\n",
    "    print (\"n = \" + str(n) + \" accuracy = \" + str(avg_accuracy) + \", time = \" + str(avg_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4 continue\n",
    "#Plot\n",
    "%matplotlib qt\n",
    "\n",
    "#Accuracy plot\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy: Neural Network on New Features\")\n",
    "plt.xlabel(\"Number of Components/Features\")\n",
    "plt.ylabel(\"Accuracy of Classification\")\n",
    "plt.plot(n_compo_range, PCA_accu_arr, marker='', linewidth=2, label=\"PCA\")\n",
    "plt.plot(n_compo_range, ICA_2_accu_arr, marker='', linewidth=2, label=\"ICA\")\n",
    "plt.plot(n_compo_range, RP_2_accu_arr, marker='', linewidth=2, label=\"RP\")\n",
    "plt.axhline(y=original_accuracy, linestyle='dashed', color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "#two ICA accuracy plots\n",
    "#n_compo_ICA was determined by the threshold values\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy: Neural Network on New Features ICA\")\n",
    "plt.xlabel(\"Number of Components/Features\")\n",
    "plt.ylabel(\"Accuracy of Classification\")\n",
    "plt.plot(n_compo_ICA, ICA_accu_arr, marker='', linewidth=2, label=\"ICA select Kurtosis\")\n",
    "plt.plot(n_compo_range, ICA_2_accu_arr, marker='', linewidth=2, label=\"ICA\")\n",
    "plt.axhline(y=original_accuracy, linestyle='dashed', color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "#RP multiple runs accuracy plot\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy: Neural Network on New Features RP Multiple Runs\")\n",
    "plt.xlabel(\"Number of Runs\")\n",
    "plt.ylabel(\"Accuracy of Classification\")\n",
    "plt.plot(RP_runs_range, RP_accu_arr, marker='', linewidth=2, label=\"ICA\")\n",
    "plt.axhline(y=original_accuracy, linestyle='dashed', color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "#Running time plot\n",
    "plt.figure()\n",
    "plt.title(\"Running time: Neural Network on New Features\")\n",
    "plt.xlabel(\"Number of Components/Features\")\n",
    "plt.ylabel(\"Accuracy of Classification\")\n",
    "plt.plot(n_compo_range, PCA_time_arr, marker='', linewidth=2, label=\"PCA\")\n",
    "plt.plot(n_compo_range, ICA_2_time_arr, marker='', linewidth=2, label=\"ICA\")\n",
    "plt.plot(n_compo_range, RP_2_time_arr, marker='', linewidth=2, label=\"RP\")\n",
    "plt.axhline(y=original_time, linestyle='dashed', color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done\n",
      "ICA done\n",
      "RP done\n"
     ]
    }
   ],
   "source": [
    "#Task 5\n",
    "#Create new data including the cluster results\n",
    "#Recall in Task 3, ICA performs the best for clustering for both K means and EM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "\n",
    "#Will focus on the Forest Fire dataset only\n",
    "df = df_set[0]\n",
    "X = X_set[0]\n",
    "labels_true = labels_true_set[0]\n",
    "dataset_name = dataset_names[0]\n",
    "\n",
    "n_compo = 5  #target number of clusters\n",
    "\n",
    "pca_X_KM_set, pca_X_EM_set = ([], [])\n",
    "ica_X_KM_set, ica_X_EM_set = ([], [])\n",
    "rp_X_KM_set, rp_X_EM_set = ([], [])\n",
    "\n",
    "#clustering on PCA results, add in new feture\n",
    "for pca_X in pca_X_set:\n",
    "    #get k means and EM clusters\n",
    "    kmeans = KMeans(n_clusters=n_compo, random_state=0).fit(pca_X)\n",
    "    em =  GaussianMixture(n_components= n_compo, max_iter = 500, random_state=0).fit(pca_X)\n",
    "    labels_pred_kmeans = kmeans.predict(pca_X)\n",
    "    labels_pred_em = em.predict(pca_X)\n",
    "    #add the clustering feature into the data\n",
    "    pca_X_KM = pca_X.copy()\n",
    "    pca_X_KM['clustering'] = labels_pred_kmeans\n",
    "    pca_X_KM_set.append(pca_X_KM)\n",
    "    pca_X_EM = pca_X.copy()\n",
    "    pca_X_EM['clustering'] = labels_pred_em\n",
    "    pca_X_EM_set.append(pca_X_EM)\n",
    "print (\"PCA done\")\n",
    "\n",
    "#clustering on ICA results, add in new feture\n",
    "for ica_X in ica_X_set:\n",
    "    #get k means and EM clusters\n",
    "    kmeans = KMeans(n_clusters=n_compo, random_state=0).fit(ica_X)\n",
    "    em =  GaussianMixture(n_components= n_compo, max_iter = 500, random_state=0).fit(ica_X)\n",
    "    labels_pred_kmeans = kmeans.predict(ica_X)\n",
    "    labels_pred_em = em.predict(ica_X)\n",
    "    #add the clustering feature into the data\n",
    "    ica_X_KM = ica_X.copy()\n",
    "    ica_X_KM['clustering'] = labels_pred_kmeans\n",
    "    ica_X_KM_set.append(ica_X_KM)\n",
    "    ica_X_EM = ica_X.copy()\n",
    "    ica_X_EM['clustering'] = labels_pred_em\n",
    "    ica_X_EM_set.append(ica_X_EM)\n",
    "print (\"ICA done\")\n",
    "\n",
    "#clustering on RP results, add in new feture\n",
    "for rp_X in rp_X_set_2:\n",
    "    #get k means and EM clusters\n",
    "    kmeans = KMeans(n_clusters=n_compo, random_state=0).fit(rp_X)\n",
    "    em =  GaussianMixture(n_components= n_compo, max_iter = 500, random_state=0).fit(rp_X)\n",
    "    labels_pred_kmeans = kmeans.predict(rp_X)\n",
    "    labels_pred_em = em.predict(rp_X)\n",
    "    #add the clustering feature into the data\n",
    "    rp_X_KM = rp_X.copy()\n",
    "    rp_X_KM['clustering'] = labels_pred_kmeans\n",
    "    rp_X_KM_set.append(rp_X_KM)\n",
    "    rp_X_EM = rp_X.copy()\n",
    "    rp_X_EM['clustering'] = labels_pred_em\n",
    "    rp_X_EM_set.append(rp_X_EM)\n",
    "print (\"RP done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA num of compos = 3 done\n",
      "PCA num of compos = 6 done\n",
      "PCA num of compos = 9 done\n",
      "PCA num of compos = 12 done\n",
      "PCA\n",
      "[0.7083172147001935, 0.7241779497098646, 0.7524177949709865, 0.7601547388781432, 0.7547388781431333, 0.7767891682785301, 0.7872340425531915, 0.7686653771760155, 0.7849129593810444, 0.7810444874274662, 0.7829787234042553, 0.774468085106383]\n",
      "[3.6715985774993896, 4.81003360748291, 5.580672025680542, 5.828806400299072, 4.261039733886719, 5.980933666229248, 5.0722503662109375, 4.741889381408692, 5.531773805618286, 4.949737787246704, 4.84015965461731, 5.070322799682617]\n",
      "PCA KM\n",
      "[0.7083172147001935, 0.723404255319149, 0.7624758220502902, 0.7644100580270793, 0.7705996131528046, 0.7705996131528046, 0.7798839458413926, 0.7678916827852998, 0.7740812379110252, 0.7880077369439071, 0.7880077369439071, 0.7880077369439072]\n",
      "[3.841371774673462, 3.568989372253418, 6.188988780975341, 4.661727046966552, 5.601650810241699, 5.289709424972534, 5.46058759689331, 4.690083789825439, 5.471415615081787, 4.959051942825317, 4.59930305480957, 5.762389993667602]\n",
      "PCA EM\n",
      "[3.3385910034179687, 4.242122983932495, 6.47191801071167, 5.1775377750396725, 5.5184284210205075, 6.300200033187866, 4.747881984710693, 4.5182231903076175, 4.850597620010376, 6.431249189376831, 4.869355821609497, 5.259363794326783]\n"
     ]
    }
   ],
   "source": [
    "#Task 5 continue\n",
    "#Run NN - PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "k = 5  #number of trials\n",
    "\n",
    "#On PCA clustering results\n",
    "pca_accu_arr, pca_KM_accu_arr, pca_EM_accu_arr = ([], [], [])\n",
    "pca_time_arr, pca_KM_time_arr, pca_EM_time_arr = ([], [], [])\n",
    "\n",
    "for j in range(0, len(pca_X_set)):\n",
    "    new_X = pca_X_set[j]\n",
    "    new_X_KM = pca_X_KM_set[j]\n",
    "    new_X_EM = pca_X_EM_set[j]\n",
    "    df_set = [new_X, new_X_KM, new_X_EM]\n",
    "    df_names = [\"PCA\", \"PCA_KM\", \"PCA_EM\"]\n",
    "    for m in range(0, 3):\n",
    "        start = time.time()\n",
    "        df = df_set[m]\n",
    "        df_name = df_names[m]\n",
    "        tot_accuracy = 0\n",
    "        for i in range (0, k):\n",
    "            clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "            clf.fit(df, labels_true)\n",
    "            predictions = clf.predict(df)\n",
    "            delta = abs(predictions - labels_true)\n",
    "            accuracy = 1 - np.mean(delta)\n",
    "            tot_accuracy = tot_accuracy + accuracy\n",
    "        accuracy = tot_accuracy/k\n",
    "        t = (time.time() - start)/k\n",
    "        if m == 0:\n",
    "            pca_accu_arr.append(accuracy)\n",
    "            pca_time_arr.append(t)\n",
    "        if m == 1:\n",
    "            pca_KM_accu_arr.append(accuracy)\n",
    "            pca_KM_time_arr.append(t)\n",
    "        if m == 2:\n",
    "            pca_EM_accu_arr.append(accuracy)\n",
    "            pca_EM_time_arr.append(t)\n",
    "    if np.remainder(j+1, 3) == 0:\n",
    "            print (\"PCA num of compos = \" + str(j+1) + \" done\")\n",
    "print (\"PCA\")\n",
    "print (pca_accu_arr)\n",
    "print (pca_time_arr)\n",
    "print (\"PCA KM\")\n",
    "print (pca_KM_accu_arr)\n",
    "print (pca_KM_time_arr)\n",
    "print (\"PCA EM\")\n",
    "print (pca_EM_time_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA iteration 3 done\n",
      "ICA iteration 6 done\n",
      "ICA\n",
      "[0.732688588007737, 0.7365570599613153, 0.7079303675048356, 0.7114119922630561, 0.7079303675048356, 0.7195357833655708, 0.7079303675048356]\n",
      "[3.769902801513672, 4.37024941444397, 1.021385383605957, 1.5894762039184571, 1.079571008682251, 4.230891370773316, 1.129565668106079]\n",
      "ICA KM\n",
      "[0.7284332688588007, 0.7292069632495164, 0.7264990328820116, 0.7264990328820117, 0.7245647969052225, 0.7226305609284334, 0.7079303675048356]\n",
      "[4.842516803741455, 3.6998830318450926, 3.93770318031311, 6.360902929306031, 5.548589563369751, 6.090720558166504, 1.059845781326294]\n",
      "ICA EM\n",
      "[0.7597678916827852, 0.7257253384912958, 0.7415860735009672, 0.7261121856866538, 0.7268858800773694, 0.7210831721470019, 0.7083172147001935]\n",
      "[6.988400411605835, 5.33152437210083, 7.062354803085327, 6.330043172836303, 5.340649557113648, 6.7194578647613525, 3.230103588104248]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Task 5 continue\n",
    "#Run NN - ICA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#On ICA clustering results\n",
    "ica_accu_arr, ica_KM_accu_arr, ica_EM_accu_arr = ([], [], [])\n",
    "ica_time_arr, ica_KM_time_arr, ica_EM_time_arr = ([], [], [])\n",
    "\n",
    "for j in range(0, len(ica_X_set)):\n",
    "    new_X = ica_X_set[j]\n",
    "    new_X_KM = ica_X_KM_set[j]\n",
    "    new_X_EM = ica_X_EM_set[j]\n",
    "    df_set = [new_X, new_X_KM, new_X_EM]\n",
    "    df_names = [\"ICA\", \"ICA_KM\", \"ICA_EM\"]\n",
    "    for m in range(0, 3):\n",
    "        df = df_set[m]\n",
    "        df_name = df_names[m]\n",
    "        tot_accuracy = 0\n",
    "        start = time.time()\n",
    "        for i in range (0, k):\n",
    "            clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "            clf.fit(df, labels_true)\n",
    "            predictions = clf.predict(df)\n",
    "            delta = abs(predictions - labels_true)\n",
    "            accuracy = 1 - np.mean(delta)\n",
    "            tot_accuracy = tot_accuracy + accuracy\n",
    "        accuracy = tot_accuracy/k\n",
    "        t = (time.time() - start)/k\n",
    "        if m == 0:\n",
    "            ica_accu_arr.append(accuracy)\n",
    "            ica_time_arr.append(t)\n",
    "        if m == 1:\n",
    "            ica_KM_accu_arr.append(accuracy)\n",
    "            ica_KM_time_arr.append(t)\n",
    "        if m == 2:\n",
    "            ica_EM_accu_arr.append(accuracy)\n",
    "            ica_EM_time_arr.append(t)\n",
    "    if np.remainder(j+1, 3) == 0:\n",
    "            print (\"ICA iteration \" + str(j+1) + \" done\")\n",
    "print (\"ICA\")\n",
    "print (ica_accu_arr)\n",
    "print (ica_time_arr)\n",
    "print (\"ICA KM\")\n",
    "print (ica_KM_accu_arr)\n",
    "print (ica_KM_time_arr)\n",
    "print (\"ICA EM\")\n",
    "print (ica_EM_accu_arr)\n",
    "print (ica_EM_time_arr)\n",
    "print (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP n_compo =3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP n_compo =6 done\n",
      "RP n_compo =9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP n_compo =12 done\n",
      "RP\n",
      "[0.7079303675048356, 0.7110251450676982, 0.7110251450676983, 0.7106382978723405, 0.7079303675048356, 0.7152804642166345, 0.711798839458414, 0.7079303675048356, 0.7079303675048356, 0.7090909090909092, 0.7098646034816247, 0.7114119922630561]\n",
      "[4.45073184967041, 4.039693355560303, 4.797753429412841, 4.920052766799927, 3.138338232040405, 6.111123418807983, 4.831844997406006, 3.649802398681641, 3.3276978492736817, 4.359951162338257, 3.6307352066040037, 5.499486351013184]\n",
      "RP KM\n",
      "[0.7079303675048356, 0.7102514506769826, 0.7098646034816248, 0.7121856866537717, 0.7079303675048356, 0.7079303675048356, 0.7125725338491297, 0.7079303675048356, 0.7087040618955512, 0.7094777562862669, 0.7083172147001935, 0.7125725338491297]\n",
      "[4.518898153305054, 4.218515205383301, 4.331560182571411, 5.060601377487183, 2.800454616546631, 2.8182868003845214, 6.038364410400391, 3.4900137901306154, 3.5017589569091796, 2.3028822422027586, 3.0213999271392824, 5.580772399902344]\n",
      "RP EM\n",
      "[0.7079303675048356, 0.7110251450676983, 0.7106382978723405, 0.7110251450676983, 0.7098646034816248, 0.7090909090909092, 0.7079303675048356, 0.7090909090909091, 0.7102514506769827, 0.7090909090909092, 0.7087040618955512, 0.7110251450676983]\n",
      "[2.6810393810272215, 4.462694406509399, 5.200653219223023, 6.760776376724243, 4.27122220993042, 2.8795352458953856, 2.9110795974731447, 3.932308006286621, 5.318722343444824, 3.838096570968628, 2.9489910125732424, 3.361907625198364]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Task 5 continue\n",
    "#Run NN - RP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#On RP clustering results\n",
    "rp_accu_arr, rp_KM_accu_arr, rp_EM_accu_arr = ([], [], [])\n",
    "rp_time_arr, rp_KM_time_arr, rp_EM_time_arr = ([], [], [])\n",
    "\n",
    "for j in range(0, len(rp_X_set_2)):\n",
    "    new_X = rp_X_set_2[j]\n",
    "    new_X_KM = rp_X_KM_set[j]\n",
    "    new_X_EM = rp_X_EM_set[j]\n",
    "    df_set = [new_X, new_X_KM, new_X_EM]\n",
    "    df_names = [\"RP\", \"RP_KM\", \"RP_EM\"]\n",
    "    for m in range(0, 3):\n",
    "        df = df_set[m]\n",
    "        df_name = df_names[m]\n",
    "        tot_accuracy = 0\n",
    "        start = time.time()\n",
    "        for i in range (0, k):\n",
    "            clf = MLPClassifier(hidden_layer_sizes=(50,)*(10))\n",
    "            clf.fit(df, labels_true)\n",
    "            predictions = clf.predict(df)\n",
    "            delta = abs(predictions - labels_true)\n",
    "            accuracy = 1 - np.mean(delta)\n",
    "            tot_accuracy = tot_accuracy + accuracy\n",
    "        accuracy = tot_accuracy/k\n",
    "        t = (time.time() - start)/k\n",
    "        if m == 0:\n",
    "            rp_accu_arr.append(accuracy)\n",
    "            rp_time_arr.append(t)\n",
    "        if m == 1:\n",
    "            rp_KM_accu_arr.append(accuracy)\n",
    "            rp_KM_time_arr.append(t)\n",
    "        if m == 2:\n",
    "            rp_EM_accu_arr.append(accuracy)\n",
    "            rp_EM_time_arr.append(t)\n",
    "    if np.remainder(j+1, 3) == 0:\n",
    "            print (\"RP n_compo =\" + str(j+1) + \" done\")\n",
    "print (\"RP\")\n",
    "print (rp_accu_arr)\n",
    "print (rp_time_arr)\n",
    "print (\"RP KM\")\n",
    "print (rp_KM_accu_arr)\n",
    "print (rp_KM_time_arr)\n",
    "print (\"RP EM\")\n",
    "print (rp_EM_accu_arr)\n",
    "print (rp_EM_time_arr)\n",
    "print (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 5 continue\n",
    "#Plot\n",
    "%matplotlib qt\n",
    "\n",
    "#Accuracy plot\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy: Neural Network on New Features including Clustering Result\")\n",
    "plt.xlabel(\"Number of Components/Features\")\n",
    "plt.ylabel(\"Accuracy of Classification\")\n",
    "#PCA: blue\n",
    "plt.plot(n_compo_range, pca_accu_arr, marker='', linewidth=2, color = 'b', label=\"PCA\")\n",
    "plt.plot(n_compo_range, pca_KM_accu_arr, marker='', linewidth=2, color = 'b', linestyle = 'dashed', label=\"PCA K means\")\n",
    "plt.plot(n_compo_range, pca_EM_accu_arr, marker='', linewidth=2, color = 'b', linestyle = 'dashdot', label=\"PCA EM\")\n",
    "#ICA: magenta (pink)\n",
    "plt.plot(n_compo_ICA, ica_accu_arr, marker='', linewidth=2, color = 'm', label=\"ICA\")\n",
    "plt.plot(n_compo_ICA, ica_KM_accu_arr, marker='', linewidth=2, color = 'm', linestyle = 'dashed', label=\"ICA K means\")\n",
    "plt.plot(n_compo_ICA, ica_EM_accu_arr, marker='', linewidth=2, color = 'm', linestyle = 'dashdot', label=\"ICA EM\")\n",
    "#RP: green\n",
    "plt.plot(n_compo_range, rp_accu_arr, marker='', linewidth=2, color = 'g', label=\"RP\")\n",
    "plt.plot(n_compo_range, rp_KM_accu_arr, marker='', linewidth=2, color = 'g', linestyle = 'dashed', label=\"RP K means\")\n",
    "plt.plot(n_compo_range, rp_EM_accu_arr, marker='', linewidth=2, color = 'g', linestyle = 'dashdot', label=\"RP EM\")\n",
    "#original_accuracy was obtained in Task 4\n",
    "plt.axhline(y=original_accuracy, marker = \"_\", linestyle='dotted', color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "#Running time plot\n",
    "plt.figure()\n",
    "plt.title(\"Running Time: Neural Network on New Features including Clustering Result\")\n",
    "plt.xlabel(\"Number of Components/Features\")\n",
    "plt.ylabel(\"Running Time\")\n",
    "#PCA: blue\n",
    "plt.plot(n_compo_range, pca_time_arr, marker='', linewidth=2, color = 'b', label=\"PCA\")\n",
    "plt.plot(n_compo_range, pca_KM_time_arr, marker='', linewidth=2, color = 'b', linestyle = 'dashed', label=\"PCA K means\")\n",
    "plt.plot(n_compo_range, pca_EM_time_arr, marker='', linewidth=2, color = 'b', linestyle = 'dashdot', label=\"PCA EM\")\n",
    "#ICA: magenta (pink)\n",
    "plt.plot(n_compo_ICA, ica_time_arr, marker='', linewidth=2, color = 'm', label=\"ICA\")\n",
    "plt.plot(n_compo_ICA, ica_KM_time_arr, marker='', linewidth=2, color = 'm', linestyle = 'dashed', label=\"ICA K means\")\n",
    "plt.plot(n_compo_ICA, ica_EM_time_arr, marker='', linewidth=2, color = 'm', linestyle = 'dashdot', label=\"ICA EM\")\n",
    "#RP: green\n",
    "plt.plot(n_compo_range, rp_time_arr, marker='', linewidth=2, color = 'g', label=\"RP\")\n",
    "plt.plot(n_compo_range, rp_KM_time_arr, marker='', linewidth=2, color = 'g', linestyle = 'dashed', label=\"RP K means\")\n",
    "plt.plot(n_compo_range, rp_EM_time_arr, marker='', linewidth=2, color = 'g', linestyle = 'dashdot', label=\"RP EM\")\n",
    "#original_time was obtained in Task 4\n",
    "plt.axhline(y=original_time, marker = \"_\", linestyle='dotted', color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
